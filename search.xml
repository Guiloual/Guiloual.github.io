<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>深度学习</title>
    <url>/2021/12/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>开个新坑，深度学习与神经网络。</p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>什么是深度学习？深度学习能用来干什么？深度学习与神经网络的关系是什么？</p>
<p>深度学习是机械学习下属的一个分支，涉及到所谓的特征提取问题，但是就深度学习而言，其本质是一个最优化的问题，即用优化算法拟合出一个函数，这个函数能够反映数据与现实世界之间的关系，例如分类问题，人脸识别以及语义识别。</p>
<p>传统的机械学习采用的是所谓的符号系统，大量特征的处理需要人工操作，这期间体现的是人工“智能”。而在引入神经网络之后，特别是2012年的反向传播算法的兴起，使得我们采用神经网络拟合函数提取特征更加容易，在这一阶段，是比较完全的“人工智能”。同时，根据非线性的神经网络的拟合定理，如果将现实世界看作一系列函数组成的世界的化，在原则上，神经网络可以拟合函数空间上的一切函数，这在理论上证明了利用神经网络构建人工智能的可行性。</p>
<p>但是采用神经网络来拟合函数也存在一系列的问题，比如对于非结构性数据的不敏感，随着神经网络层数的增加，导致整个神经网络的鲁棒性降低，泛化能力减弱以及计算成本的上升，这些问题都阻碍着深度学习的发展，即使有深度学习领域的工作人员通过各种方法解决这些问题，但总的来说，并没有一个通用的方法彻底解决这些问题，并且现在人工智能进入了新的瓶颈期，人工智能并没有达到人们的预期，未来发展还是世事难料。</p>
<h2 id="一些名词解释"><a href="#一些名词解释" class="headerlink" title="一些名词解释"></a>一些名词解释</h2><p>以上引言出现了大量的关于机械学习方面的名词，我们首先解释一下这些名词的意思。</p>
<p>首先我们谈论一下关于特征学习和特征提取的问题。</p>
<p>所谓特征学习，就是通过分析现实世界的结构性或非结构性的数据，提取出最能表示事物规律的数据，并对这些数据赋予权重，利用这些权重给各个数据进行打分，特征学习就是学习这些特征的权重。</p>
<p>特征提取，就是对上述所说的结构性或非结构性数据中的与现实世界之间有关联的数据进行提取。</p>
<p>上面的表述之中有出现了新的名词，即结构性的数据和非结构性的数据，我在这里做出解释。</p>
<p>所谓结构性的数据，即数据在排列过程中出现的一系列的有规律性数据组合，例如我们的房价与所在地的一组数据就是非常典型的结构性数据。非结构性数据，即数据在表示中出现的一种没有明确规律的数据，我们平时所用的语言就是典型的非结构性数据。</p>
<p>后续名词会在出现时给出明确的定义。</p>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>在关于机械学习或着说是深度学习的几乎每本书，在真正开始讨论矩体的机械学习方法之前都会介绍线性回归模型，在机械学习里面，经典的线性回归模型有：逻辑回归、支持向量机和感知机，emmm，后面两种没怎么实操过（主要我看的书很少运用到这两种模型，不过并不代表着这两种模式不重要，事实上，这两种模型在语意识别等领域非常常用），待我仔细研读操作后才来更新后面的两种模型。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>今天就到这儿吧，明天再来更新逻辑回归，以及再python上如何用手撸出逻辑回归的实现代码。</p>
]]></content>
  </entry>
  <entry>
    <title>2021.12.28第一步</title>
    <url>/2021/12/28/2021-12-28%E7%AC%AC%E4%B8%80%E6%AD%A5/</url>
    <content><![CDATA[<h2 id="Blog建站感言"><a href="#Blog建站感言" class="headerlink" title="Blog建站感言"></a>Blog建站感言</h2><p>2021.12.28日，经过了一个下午的调试，我的第一个属于自己的blog搭建起来了🎉🎉🎉🎉</p>
<p>这个blog也不是多么的高大上，也就是发发牢骚，分享分享学习历程，以及总结反思（自娱自乐 逃）的地方，我开启了评论功能，我们可以在评论区讨论一些有意思的东西（在遵守法律的情况下 逃）😁😁😁</p>
<p>建站愉快🎉🎉🎉🎉</p>
]]></content>
  </entry>
  <entry>
    <title>逻辑回归</title>
    <url>/2021/12/30/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<p>今天的内容为逻辑回归</p>
<h1 id="逻辑回归模型"><a href="#逻辑回归模型" class="headerlink" title="逻辑回归模型"></a>逻辑回归模型</h1><p>Logistic回归（Logistic Regression，LR）是一种十分常用的处理二分类问题的线性模型。</p>
<h2 id="符号约定"><a href="#符号约定" class="headerlink" title="符号约定"></a>符号约定</h2><p>我们对本节符号做如下约定：</p>
<table>
<thead>
<tr>
<th align="left">符号</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">$p(\cdot)$</td>
<td align="center">概率</td>
</tr>
<tr>
<td align="left">$p(A</td>
<td align="center">B)$</td>
</tr>
<tr>
<td align="left">$g(\cdot)$</td>
<td align="center">激活函数（activation function）</td>
</tr>
<tr>
<td align="left">$\exp(\cdot)$</td>
<td align="center">指数函数</td>
</tr>
<tr>
<td align="left">$x = [x_1,x_2,\cdots,x_d]^T$</td>
<td align="center">$\mathbb{R}^d$中的d维特征向量</td>
</tr>
<tr>
<td align="left">$x =[x_1,x_2,\cdots,x_d,1]^T$</td>
<td align="center">增广特征向量</td>
</tr>
<tr>
<td align="left">$w = [w_1,w_2,\cdots,w_d]$</td>
<td align="center">权重向量</td>
</tr>
<tr>
<td align="left">$d$</td>
<td align="center">偏置</td>
</tr>
<tr>
<td align="left">$\log(\cdot)$</td>
<td align="center">对数函数</td>
</tr>
</tbody></table>
<h2 id="逻辑回归的数学模型"><a href="#逻辑回归的数学模型" class="headerlink" title="逻辑回归的数学模型"></a>逻辑回归的数学模型</h2><p>如上所说，逻辑回归是一种二分类模型，如果我们想要进行分类，那么我们最后要得到的函数就应当是一个二值函数，并且划分出所谓的决策平面。</p>
<p>为了达到上述目的，我们引入非线性函数函数来预测输入数据的标签后验概率$p(y=1|x)$:<br>$$<br>p(y=1|x) = g(f(x;w,b))<br>$$<br>非线性的激活函数$g(\cdot)$的作用是将实数空间$\mathbb{R}$中的数压缩到$[0,1]$区间上，我们将数据经过函数后得到的值作为其等于标签$1$的后验概率，并且在上述表达式中$w$和$b$是我们要学习的参数。<br>$$<br>f(x;w,b) = wx+b<br>$$<br>上式在神经网络中又称为线性运算单元，作用只是对各个数据赋予权值，并且加上一个偏差，权重$w$可以理解为特征提取。</p>
<p>我们选择$sigmoid(\cdot)$函数作为激活函数，$sigmiod$函数的表达式为：<br>$$<br>\sigma(x) = \frac{1}{1+\exp(-x)}<br>$$<br>我们可以验证$\sigma(x)$是落在$[0,1]$区间的。在Logistic回归中，我们用来预测标签后验概率：<br>$$<br>p(y=1|x) = \sigma(f(x;w,b)) = \frac{1}{1+\exp(-f(x;w,b))}<br>$$<br>我们采用极大似然估计数据的真实标签，我们约定$y\in{0,1}$：</p>
<p>…….期末复习，停更……..</p>
]]></content>
  </entry>
</search>
